{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the URL for Sending a POST request to the Applet created for this purpose\n",
    "\n",
    "# https://ifttt.com/maker_webhooks/settings\n",
    "\n",
    "# URL given in the above link: https://maker.ifttt.com/use/olYyWzU82vyL3qxlOZB9YUHKXyzXm8-au1rKhsGUNXQ\n",
    "\n",
    "#'https://maker.ifttt.com/trigger/news_event/with/key/olYyWzU82vyL3qxlOZB9YUHKXyzXm8-au1rKhsGUNXQ'\n",
    "\n",
    "#https://github.com/dbader/schedule/issues/209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we again use ifttt to deliver suggested articles to personal emailids\n",
    "# For Making Applet, Use if this then that - for \"if\", use Maker (in that choose \"recieve a web request\" and type \"news_event\" and click crete trigger) (recieves POST request)and \"then\" use \"Gmail\" (in that select send an email) (have to authorize first, i.e. allow the app to access Gmail - just follow instuctions to authorize)\n",
    "# For Gmail, u can then customize the body and message - added mom's email address, {Value1} which represents title and {Value2} which represents URL of thee news article\n",
    "# craete a function and schedule it to run for every 60 minutes.\n",
    "# In that fucntion, (first steps are same - download using gspread, use beautiful soup and predict tag) if u get a new news artcile in the spreadsheet, then we embed the title and url of it in a json string called Value1 and make a post request (that includes the data) to this new applet created in the ifttt ('https://maker.ifttt.com/trigger/news_event/with/key/olYyWzU82vyL3qxlOZB9YUHKXyzXm8-au1rKhsGUNXQ') - key is from got on making the applet\n",
    "# this causes the app to send an email to the inbox\n",
    "# Clean up the worksheet after this tto get new articles every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import schedule\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import gspread\n",
    "import requests\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.max_colwidth',250)\n",
    "\n",
    "def fetch_news():\n",
    "    try:\n",
    "        vect = pickle.load(open(r'/Users/rishitdholakia/Desktop/Projects/Cooking News Feed/vect_pickle.p','rb'))\n",
    "        model = pickle.load(open(r'/Users/rishitdholakia/Desktop/Projects/Cooking News Feed/model_pickle.p','rb'))\n",
    "    \n",
    "        scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "        credentials=ServiceAccountCredentials.from_json_keyfile_name(r'/Users/rishitdholakia/Desktop/Projects/Cooking News Feed/riya-latest-project-0add4349491b.json',scopes=scope)\n",
    "        gc=gspread.authorize(credentials)\n",
    "        \n",
    "        ws = gc.open(\"CookingArticles\")\n",
    "        # Or sheet = gc.open('CookingArticles').sheet1\n",
    "        sh=ws.sheet1\n",
    "        zd=list(zip(sh.col_values(2),sh.col_values(3),sh.col_values(4)))\n",
    "        zf=pd.DataFrame(zd,columns=['title','urls','html'])\n",
    "        zf.replace('',pd.np.nan,inplace=True)\n",
    "        zf.dropna(inplace=True)\n",
    "                            \n",
    "        def get_text(x):\n",
    "            soup=BeautifulSoup(x,'lxml')\n",
    "            text=soup.get_text()\n",
    "            return text\n",
    "                            \n",
    "        df.loc[:,'text']=df['html'].map(get_text)\n",
    "                            \n",
    "        tv=vect.transform(zf['text'])\n",
    "        res=model.predict(tv)\n",
    "                            \n",
    "        rf=pd.DataFrame(res,columns=['wanted'])\n",
    "        rez=pd.merge(rf,zf,left_index=True,right_index=True)\n",
    "                            \n",
    "        news_str=''\n",
    "        for t,u in zip(rez[rez['wanted']=='y']['title'],rez[rez['wanted']=='y']['urls']):\n",
    "            news_str=news_str + t +'\\n'+ u + '\\n'\n",
    "                            \n",
    "        payload = {\"value1\" : news_str}\n",
    "        r = requests.post('https://maker.ifttt.com/trigger/news_event/with/key/olYyWzU82vyL3qxlOZB9YUHKXyzXm8-au1rKhsGUNXQ',data=payload)\n",
    "                            \n",
    "        #Clean Up Worksheet\n",
    "        lenv = len(sh.col_values(1))\n",
    "        cell_list=sh.range('A1:F' + str(lenv))\n",
    "        for cell in cell_list:\n",
    "            cell.value=''\n",
    "        sh.update_cells(cell_list)\n",
    "                            \n",
    "        print(r.text)\n",
    "    \n",
    "    except:\n",
    "        print('Failed')\n",
    "    \n",
    "schedule.every(5).minutes.do(fetch_news)\n",
    "                            \n",
    "while 1:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
